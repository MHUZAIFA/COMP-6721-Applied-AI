{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a29592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54f3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Feature Extractor (Color Histogram) ==========\n",
    "def extract_features(image, bins=32, resize_dim=(64, 64)):\n",
    "    image = image.resize(resize_dim).convert('RGB') # Ensures that all images are RGB\n",
    "    image_np = np.array(image)\n",
    "    hist_r = np.histogram(image_np[:, :, 0], bins=bins, range=(0, 256))[0]\n",
    "    hist_g = np.histogram(image_np[:, :, 1], bins=bins, range=(0, 256))[0]\n",
    "    hist_b = np.histogram(image_np[:, :, 2], bins=bins, range=(0, 256))[0]\n",
    "    hist = np.concatenate([hist_r, hist_g, hist_b])\n",
    "    return hist / np.sum(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image, resize_dim=(64, 64), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "    image = image.resize(resize_dim).convert('RGB')\n",
    "    gray = rgb2gray(np.array(image))\n",
    "    features = hog(gray, orientations=orientations,\n",
    "                   pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block,\n",
    "                   block_norm='L2-Hys')\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def extract_combined_features(image):\n",
    "    hog_feat = extract_hog_features(image)\n",
    "    hist_feat = extract_features(image)\n",
    "    return np.concatenate([hog_feat, hist_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25798c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Load data ===\n",
      "Train shape: (15000, 12288), Test shape: (300, 12288)\n",
      "Classes: ['library-indoor' 'museum-indoor' 'shopping_mall-indoor']\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "image_size = (64, 64)  # Resize all images to 64x64\n",
    "valid_exts = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "# Function to load images from a given folder\n",
    "def load_dataset(root_dir, extractor_fn):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "    for label in class_names:\n",
    "        label_path = os.path.join(root_dir, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        for fname in os.listdir(label_path):\n",
    "            if fname.lower().endswith(valid_exts):\n",
    "                try:\n",
    "                    img_path = os.path.join(label_path, fname)\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    if extractor_fn == None:\n",
    "                        img = img.resize(image_size)\n",
    "                        img_array = np.array(img).flatten()  # Flatten to 1D vector (64*64*3)\n",
    "                        X.append(img_array)\n",
    "                        y.append(label)\n",
    "                    else:\n",
    "                        features = extractor_fn(img)\n",
    "                        X.append(features)\n",
    "                        y.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load training and testing data\n",
    "print(\"=== Load data ===\")\n",
    "func_name = None #extract_features #combined features\n",
    "X_train, y_train = load_dataset(\"Training\", func_name)\n",
    "X_test, y_test = load_dataset(\"Test\", func_name)\n",
    "\n",
    "# Encode labels (e.g., 'library' -> 0, etc.)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Shuffle and standardize\n",
    "X_train, y_train_enc = shuffle(X_train, y_train_enc, random_state=42)\n",
    "X_test, y_test_enc = shuffle(X_test, y_test_enc, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0889020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Training ---\n"
     ]
    }
   ],
   "source": [
    "# ---- Random Forest ---- Dont run this for now\n",
    "print(\"\\n--- Random Forest Training ---\")\n",
    "rf_params = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15], 'criterion': ['gini','entropy'],'min_samples_split': [5, 10],\n",
    "             'min_samples_leaf': [5, 10], 'random_state': [None,42]}\n",
    "rf = GridSearchCV(RandomForestClassifier(), rf_params, scoring='accuracy')\n",
    "rf.fit(X_train, y_train_enc)\n",
    "rf_preds = rf.predict(X_test)\n",
    "print(classification_report(y_test_enc, rf_preds))\n",
    "print(confusion_matrix(y_test_enc, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Training ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55       100\n",
      "           1       0.65      0.59      0.62       100\n",
      "           2       0.57      0.68      0.62       100\n",
      "\n",
      "    accuracy                           0.60       300\n",
      "   macro avg       0.60      0.60      0.60       300\n",
      "weighted avg       0.60      0.60      0.60       300\n",
      "\n",
      "[[52 19 29]\n",
      " [18 59 23]\n",
      " [19 13 68]]\n"
     ]
    }
   ],
   "source": [
    "# ---- Random Forest ----\n",
    "print(\"\\n--- Random Forest Training ---\")\n",
    "# rf_params = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15], 'criterion': ['gini','entropy'],'min_samples_split': [2, 5]}\n",
    "rf = RandomForestClassifier(n_estimators= 120, \n",
    "                            max_depth= 9, \n",
    "                            criterion= \"gini\", \n",
    "                            min_samples_split= 2,\n",
    "                            min_samples_leaf=1,\n",
    "                            max_features='sqrt',\n",
    "                            random_state=None)\n",
    "rf.fit(X_train, y_train_enc)\n",
    "rf_preds = rf.predict(X_test)\n",
    "print(classification_report(y_test_enc, rf_preds))\n",
    "print(confusion_matrix(y_test_enc, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183ff528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      5000\n",
      "           1       0.90      0.77      0.83      5000\n",
      "           2       0.80      0.89      0.84      5000\n",
      "\n",
      "    accuracy                           0.84     15000\n",
      "   macro avg       0.85      0.84      0.84     15000\n",
      "weighted avg       0.85      0.84      0.84     15000\n",
      "\n",
      "[[4338  188  474]\n",
      " [ 502 3841  657]\n",
      " [ 307  257 4436]]\n"
     ]
    }
   ],
   "source": [
    "rf_preds_train = rf.predict(X_train)\n",
    "print(classification_report(y_train_enc, rf_preds_train))\n",
    "print(confusion_matrix(y_train_enc, rf_preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a02e545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50} --> mean: 0.5142, std: 0.0085\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100} --> mean: 0.5124, std: 0.0069\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200} --> mean: 0.5115, std: 0.0076\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 50} --> mean: 0.5139, std: 0.0098\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100} --> mean: 0.5113, std: 0.0058\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200} --> mean: 0.5149, std: 0.0078\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50} --> mean: 0.5383, std: 0.0079\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100} --> mean: 0.5452, std: 0.0063\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200} --> mean: 0.5485, std: 0.0079\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50} --> mean: 0.5375, std: 0.0058\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100} --> mean: 0.5465, std: 0.0084\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200} --> mean: 0.5536, std: 0.0070\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50} --> mean: 0.5263, std: 0.0087\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100} --> mean: 0.5467, std: 0.0094\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200} --> mean: 0.5625, std: 0.0048\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50} --> mean: 0.5354, std: 0.0100\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100} --> mean: 0.5487, std: 0.0066\n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200} --> mean: 0.5577, std: 0.0040\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50} --> mean: 0.5096, std: 0.0075\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100} --> mean: 0.5115, std: 0.0069\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200} --> mean: 0.5125, std: 0.0081\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 50} --> mean: 0.5090, std: 0.0090\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100} --> mean: 0.5094, std: 0.0061\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 200} --> mean: 0.5137, std: 0.0061\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50} --> mean: 0.5367, std: 0.0073\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100} --> mean: 0.5468, std: 0.0036\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200} --> mean: 0.5517, std: 0.0066\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50} --> mean: 0.5365, std: 0.0076\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100} --> mean: 0.5463, std: 0.0062\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200} --> mean: 0.5497, std: 0.0083\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50} --> mean: 0.5359, std: 0.0041\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100} --> mean: 0.5503, std: 0.0037\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200} --> mean: 0.5621, std: 0.0099\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50} --> mean: 0.5358, std: 0.0063\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100} --> mean: 0.5501, std: 0.0057\n",
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200} --> mean: 0.5611, std: 0.0052\n"
     ]
    }
   ],
   "source": [
    "results = rf.cv_results_\n",
    "for mean, std, params in zip(results[\"mean_test_score\"],\n",
    "                              results[\"std_test_score\"],\n",
    "                              results[\"params\"]):\n",
    "    print(f\"{params} --> mean: {mean:.4f}, std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6270f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26da037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
