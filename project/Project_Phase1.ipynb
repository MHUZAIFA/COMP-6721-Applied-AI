{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a29592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Feature Extractor (Color Histogram) ==========\n",
    "def extract_features(image, bins=32, resize_dim=(64, 64)):\n",
    "    image = image.resize(resize_dim).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    hist_r = np.histogram(image_np[:, :, 0], bins=bins, range=(0, 256))[0]\n",
    "    hist_g = np.histogram(image_np[:, :, 1], bins=bins, range=(0, 256))[0]\n",
    "    hist_b = np.histogram(image_np[:, :, 2], bins=bins, range=(0, 256))[0]\n",
    "    hist = np.concatenate([hist_r, hist_g, hist_b])\n",
    "    return hist / np.sum(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image, resize_dim=(64, 64), orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "    image = image.resize(resize_dim).convert('RGB')\n",
    "    gray = rgb2gray(np.array(image))\n",
    "    features = hog(gray, orientations=orientations,\n",
    "                   pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block,\n",
    "                   block_norm='L2-Hys')\n",
    "    return features\n",
    "\n",
    "def extract_combined_features(image):\n",
    "    hog_feat = extract_hog_features(image)\n",
    "    hist_feat = extract_features(image)\n",
    "    return np.concatenate([hog_feat, hist_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25798c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_size = (64, 64)  # Resize all images to 64x64\n",
    "valid_exts = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "# Function to load images from a given folder\n",
    "def load_dataset(root_dir, extractor_fn):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "    for label in class_names:\n",
    "        label_path = os.path.join(root_dir, label)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        for fname in os.listdir(label_path):\n",
    "            if fname.lower().endswith(valid_exts):\n",
    "                try:\n",
    "                    img_path = os.path.join(label_path, fname)\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    if extractor_fn == None:\n",
    "                        img = img.resize(image_size)\n",
    "                        img_array = np.array(img).flatten()  # Flatten to 1D vector (64*64*3)\n",
    "                        X.append(img_array)\n",
    "                        y.append(label)\n",
    "                    else:\n",
    "                        features = extractor_fn(img)\n",
    "                        X.append(features)\n",
    "                        y.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load training and testing data\n",
    "print(\"=== Load data ===\")\n",
    "func_name = extract_combined_features #extract_features #extract_combined_features #None\n",
    "X_train, y_train = load_dataset(\"Training\", func_name)\n",
    "X_test, y_test = load_dataset(\"Test\", func_name)\n",
    "\n",
    "# Encode labels (e.g., 'library' -> 0, etc.)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Shuffle and standardize\n",
    "X_train, y_train_enc = shuffle(X_train, y_train_enc, random_state=42)\n",
    "X_test, y_test_enc = shuffle(X_test, y_test_enc, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0889020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- SVM ---- individual models\n",
    "print(\"\\n--- SVM Training ---\")\n",
    "svm_classifier = SVC(kernel='rbf', C=1, random_state=42, degree= 8, probability=True)\n",
    "svm_classifier.fit(X_train, y_train_enc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a5f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##=== Training Performance SVM===\n",
    "print('=== Training Performance SVM===')\n",
    "svm_preds_train = svm_classifier.predict(X_train)\n",
    "print(classification_report(y_train_enc, svm_preds_train))\n",
    "print(confusion_matrix(y_train_enc, svm_preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Testing Performance SVM ===')\n",
    "svm_preds = svm_classifier.predict(X_test)\n",
    "print(classification_report(y_test_enc, svm_preds))\n",
    "print(confusion_matrix(y_test_enc, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Random Forest ----\n",
    "print(\"\\n--- Random Forest Training ---\")\n",
    "# rf_params = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15], 'criterion': ['gini','entropy','log_loss'],'min_samples_split': [2, 5]}\n",
    "rf = RandomForestClassifier(n_estimators= 100, \n",
    "                            max_depth= 9,\n",
    "                            criterion= \"entropy\", \n",
    "                            min_samples_split= 5,\n",
    "                            min_samples_leaf=5,\n",
    "                            max_features='sqrt',\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e138a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Training Performance RF ===')\n",
    "rf_preds_train = rf.predict(X_train)\n",
    "print(classification_report(y_train_enc, rf_preds_train))\n",
    "print(confusion_matrix(y_train_enc, rf_preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Testing Performance RF ===')\n",
    "rf_preds = rf.predict(X_test)\n",
    "print(classification_report(y_test_enc, rf_preds))\n",
    "print(confusion_matrix(y_test_enc, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Semi-Supervised Tree ==========\n",
    "\n",
    "n_iter=25\n",
    "confidence_thresh=0.95\n",
    "np.random.seed(422)\n",
    "max_add_fraction = 0.05 # add 10% of the total samples\n",
    "\n",
    "max_add_count = int(max_add_fraction * len(X_train))\n",
    "total_idx = np.arange(len(X_train))\n",
    "labeled_idx = np.random.choice(total_idx, size=int(0.2 * len(X_train)), replace=False)\n",
    "unlabeled_idx = np.setdiff1d(total_idx, labeled_idx)\n",
    "\n",
    "y_pseudo = y_train_enc.copy()\n",
    "clf = DecisionTreeClassifier(criterion='entropy', \n",
    "                             max_depth=10, \n",
    "                             min_samples_split=5, \n",
    "                             min_samples_leaf=5,\n",
    "                             random_state=42, \n",
    "                             max_leaf_nodes=None)\n",
    "\n",
    "print(f\"Starting Semi-Supervised Learning:\")\n",
    "print(f\"Initial: {len(labeled_idx)} labeled, {len(unlabeled_idx)} unlabeled\")\n",
    "\n",
    "    \n",
    "for i in range(n_iter):\n",
    "    clf.fit(X_train[labeled_idx], y_pseudo[labeled_idx])\n",
    "    probs = clf.predict_proba(X_train[unlabeled_idx])\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    max_conf = np.max(probs, axis=1)\n",
    "\n",
    "    confident_idx = np.where(max_conf >= confidence_thresh)[0]\n",
    "    if len(confident_idx) == 0:\n",
    "        break\n",
    "\n",
    "    if len(confident_idx) > max_add_count:\n",
    "        confident_idx = confident_idx[:max_add_count]\n",
    "    \n",
    "    confident_unlabeled = unlabeled_idx[confident_idx]\n",
    "    y_pseudo[confident_unlabeled] = preds[confident_idx]\n",
    "    \n",
    "    labeled_idx = np.concatenate([labeled_idx, confident_unlabeled])\n",
    "    unlabeled_idx = np.setdiff1d(unlabeled_idx, confident_unlabeled)\n",
    "    print(f\"- Iteration {i + 1}: Added {len(confident_unlabeled)} pseudo-labeled samples. \"\n",
    "              f\"{len(unlabeled_idx)} unlabeled remain.\")\n",
    "    \n",
    "    if unlabeled_idx.size==0:\n",
    "        break\n",
    "\n",
    "# clf.fit(X_train[labeled_idx], y_pseudo[labeled_idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ddae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Training Performance DT ===')\n",
    "preds_train = clf.predict(X_train[labeled_idx])\n",
    "print(classification_report(y_train_enc[labeled_idx], preds_train))\n",
    "print(confusion_matrix(y_train_enc[labeled_idx], preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Testing Performance DT ===')\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test_enc, preds))\n",
    "print(confusion_matrix(y_test_enc, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba44eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6308cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train and y_train should already be defined\n",
    "selector = SelectKBest(score_func=f_classif, k=200)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train_enc)\n",
    "X_test_selected = selector.transform(X_test)  # Use the same selector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
